{
    "vocab_size": 50000,
    "max_seq_length": 2048,
    "hidden_size": 768,
    "num_layers": 12,
    "num_heads": 12,
    "batch_size": 1,
    "num_epochs": 10,
    "attention": {
        "use_flash_attention": true,
        "use_rope": true,
        "use_sliding_window": false,
        "window_size": 512,
        "use_gqa": false,
        "num_kv_heads": 6
    }
} 
{
    "model": {
        "vocab_size": 32000,
        "hidden_size": 128,
        "num_heads": 4,
        "num_layers": 2,
        "head_dim": 42,
        "intermediate_size": 512,
        "max_seq_length": 32
    },
    "training": {
        "batch_size": 32, 
        "num_epochs": 6,
        "dropout_rate": 0.1,
        "weight_decay": 0.01
    },
    "attention": {
        "use_flash_attention": true,
        "use_rope": true,
        "use_sliding_window": false,
        "window_size": 32,
        "use_gqa": true,
        "num_kv_heads": 2
    },
    "optimization": {
        "use_fp16": true,
        "use_gradient_checkpointing": false,
        "memory_pool_size": 512
    },
    "paths": {
        "save_directory": "models",
        "model_name": "transformer_new_corpus",
        "checkpoint_frequency": 2
    },
    "beam_search": {
        "beam_size": 5,
        "length_penalty": 0.6,
        "temperature": 0.8,
        "diversity_strength": 0.5,
        "top_k": 40,
        "top_p": 0.9,
        "max_length": 1
    },
    "load_from_checkpoint": false,
    "checkpoint_to_load": ""
} 